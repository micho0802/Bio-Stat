---
title: "Alternative analysis of postural sway data"
format: 
  html:
    embed-resources: true
execute: 
  error: true
---

This program runs some alternatives to the two-sample t-test. Consult the [data dictionary][dic] for information about the data itself.

[dic]: https://github.com/pmean/data/blob/main/files/postural-sway.yaml


## Libraries

```{r setup}
#| message: false
#| warning: false
library(tidyverse)
```

## Read data

```{r read-sway}
sway <- read_tsv(
  file="../data/postural-sway.txt",
  col_types="cnn")
names(sway) <- tolower(names(sway))
glimpse(sway)
```

## Question 1
The side-to-side sway data appears to have a pair of outliers and some evidence of heterogenity. Use a log transformation to see if this makes things better. Analyze the data on a log scale using a two-sample t-test and report the confidence interval after transforming back to the original scale of measurement.

## Boxplot of side-to-side sway by age

```{r boxplot-1}
#| fig.height: 2
#| fig.width: 6
sway |>
  ggplot(aes(age, sidesway)) +
    geom_boxplot() +
    ggtitle("Graph drawn by Michael Dang on 2024-10-22") +
    xlab("Treatment group") +
    ylab("Side to side sway") +
    coord_flip()
```

The outlier causes some concern about the validity of the two-sample t-test.

## Descriptive statistics for side-to-side sway by age

```{r group-means}
sway |>
  group_by(age) |>
  summarize(
    sts_mn=mean(sidesway),
    sts_sd=sd(sidesway),
    n=n())
```

In addition to the outlier, notice that the group with the larger mean (elderly) has the larger standard deviation. This indicates that a log transformation may produce better results.

## Log transformation, 1

```{r log-transform-1}
sway |>
  mutate(log_sidesway=log10(sidesway)) -> log_sway
```

## Log transformation, 2

```{r log-transform-2}
#| fig.height: 2
#| fig.width: 6
log_sway |>
  ggplot(aes(age, log_sidesway)) +
    geom_boxplot() +
    ggtitle("Graph drawn by Steve Simon on 2024-10-13") +
    xlab("Treatment group") +
    ylab("Side to side sway") +
    coord_flip()
```

There are no outliers after a log transformation.

## Log transformation, 3

```{r compare-means-on-log-scale}
log_sway |>
  group_by(age) |>
  summarize(
    log_mn=mean(log_sidesway),
    log_sd=sd(log_sidesway),
    n=n())
```

The standard deviations on the log scale are quite a bit more similar than they were on the original scale.

## Two-sample t-test using the log transformation

```{r t-test}
m2 <- t.test(
  log_sidesway ~ age, 
  data=log_sway,
  alternative="two.sided",
  var.equal=TRUE)
m2
```

There is a statistically significant difference between the log side-to-side sway between elderly patients and young patients. The confidence interval will be interpreted after transforming back to the original scale of measurement.

## Back-transform confidence interval to the original scale.

```{r back-transform}
10^(m2$conf.int)
```

We are 95% confident that the geometric mean side-to-side sway in elderly patients is somewhere between 0.96 times and 2.02 times that of the geometric mean for young patients. This suggests that there is no statistically significant difference between the groups, as the interval includes values below 1, which implies that the sway in elderly patients could potentially be lower than that in younger patients.

## Mann-Whitney-Wilcoxon

```{r nonparametric-test}
wilcox.test(sidesway ~ age, data=sway)
```

Since the p-value is small, you would reject the null hypothesis and conclude that there is a statistically significant difference in side-to-side sway values between elderly and young patients.


## Question 2
You want to replicate these findings in a new population, using the log transformation on the new data. Select a standard deviation from log transformed side-to-side sway values in the current study (go halfway between the two standard deviations). You want to have 90% power for detecting a 1.5 fold change (which is 0.176 units on a log base 10 scale). If you use a two-sided hypothesis with alpha = 0.05, what sample size would you need?

```{r power-1}
power.t.test(
  n=NULL,
  delta=0.176,
  sd=0.149, # (0.1119424 + 0.1869584) / 2
  sig.level=0.05,
  power=0.9,
  type="two.sample",
  alternative="two.sided")
```

The sample size is 16.